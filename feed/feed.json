{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Missing the forest for the trees",
  "language": "en",
  "home_page_url": "https://guitargz.github.io/",
  "feed_url": "https://guitargz.github.io/feed/feed.json",
  "description": "I am writing of stuff I learn every day",
  "author": {
    "name": "guitargz",
    "url": "https://guitargz.github.io/about-me/"
  },
  "items": [{
      "id": "https://guitargz.github.io/posts/202105071657-wsl2-gui/",
      "url": "https://guitargz.github.io/posts/202105071657-wsl2-gui/",
      "title": "GUI Linux apps in WSL2",
      "content_html": "<p>In Windows 10 Insiders Preview build 21364 it is now <a href=\"https://devblogs.microsoft.com/commandline/the-initial-preview-of-gui-app-support-is-now-available-for-the-windows-subsystem-for-linux-2/\">possible</a> to run Linux GUI apps in WSL2.<br>\nSwitched to the Dev channel in order to try. So far so good! Windows still runs fast and stable in my applications. The Linux apps (I've used Firefox and Burp Suite) also run fine.<br>\n<br /><br>\nThe issues I've noticed so far (hope it is fixed soon):</p>\n<ul>\n<li>Sometimes copy/paste stops working from Windows to Linux. The reversed direction works OK.</li>\n<li>The touchpad of my Dell XPS 9370 is not so pleasant to use in the Linux apps. The movement is not so smooth and the reaction is not that precise.<br>\n<br /><br>\n<img src=\"https://i.imgur.com/nQ2juqf.png\" alt=\"Firefox in Windows and Linux side-by-side\" title=\"Firefox in Windows and Linux side-by-side\"></li>\n</ul>\n",
      "date_published": "2021-05-05T00:00:00Z"
    },{
      "id": "https://guitargz.github.io/posts/202105051646-tryhackme/",
      "url": "https://guitargz.github.io/posts/202105051646-tryhackme/",
      "title": "TryHackMe",
      "content_html": "<p>Having fun with <a href=\"https://tryhackme.com/\">TryHackMe</a>. The idea behind is great and simple: there are lots of rooms dedicated to specific hacking topics. In the rooms you can deploy a virtual machine on which you can practice.<br>\n<br /><br>\n<a href=\"https://www.youtube.com/watch?v=xl2Xx5YOKcI\">Here</a> is a good example of a basic penetration testing by John Hammond.<br>\n<br /></p>\n<div class=\"video-wrap\">\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/xl2Xx5YOKcI\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>",
      "date_published": "2021-05-05T00:00:00Z"
    },{
      "id": "https://guitargz.github.io/posts/202104151136-neural-network-telegram-bot/",
      "url": "https://guitargz.github.io/posts/202104151136-neural-network-telegram-bot/",
      "title": "Neural Network Telegram Bot",
      "content_html": "<h1 id=\"neural-network-telegram-bot-with-stylegan-and-gpt-2\">Neural network Telegram bot with StyleGAN and GPT-2 <a class=\"direct-link\" href=\"#neural-network-telegram-bot-with-stylegan-and-gpt-2\">#</a></h1>\n<h2 id=\"the-beginning\">The Beginning <a class=\"direct-link\" href=\"#the-beginning\">#</a></h2>\n<p>So we have already played with different neural networks. Cursed image generation using GANs, deep texts from GPT-2 â€” we have seen it all. <br>\n<br>\nThis time I wanted to create a neural entity that would act like a beauty blogger. This meant it would have to post pictures like Instagram influencers do and generate the same kind of narcissistic texts. <br>\n<br>\nInitially I planned to post the neural content on Instagram but using the Facebook Graph API which is needed to go beyond read-only was too painful for me. So I reverted to Telegram which is one of my favorite social products overall. <br>\n<br>\nThe name of the entity/channel (Aida Enelpi) is a bad neural-oriented pun mostly generated by the bot itself.</p>\n<p><img src=\"/img/aida_1.png\" alt=\"One of the first posts generated by Aida\" title=\"One of the first posts generated by Aida\"><br>\n<br /><br /></p>\n<h2 id=\"stylegan\">StyleGAN <a class=\"direct-link\" href=\"#stylegan\">#</a></h2>\n<p>I really liked the <a href=\"https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v3.ipynb\">BigGAN results</a> at generating images but I understood it would take too much compute power to transfer learn such a model on either my PC or Colab/Kaggle. <br>\n<br>\nSo I took the beautiful <a href=\"https://github.com/ak9250/stylegan-art\">Stylegan-art repository</a> as the basis for my training. My <a href=\"https://www.kaggle.com/guitargz/stylegan-social/edit/run/58632173\">Kaggle </a> also used the model trained by StyleGAN-art as the initial point for transfer learning. I chose Kaggle over Colab because normally you get better GPUs in the free version. <br>\n<br>\nI took the available <a href=\"https://www.kaggle.com/prithvijaunjale/instagram-images-with-captions\">Instagram dataset</a> and reduced it to 7000 512x512 images not to go out of memory during the training.<br>\n<br /> <br /></p>\n<p><img src=\"https://i.imgur.com/vuJmqTr.gif\" alt=\"Transfer learning\" title=\"Transfer learning\"></p>\n<br />\nI think the quality of training has suffered due to a lot of different image types (selfies, full persons, cats, food, etc.) in the dataset. I plan to create more specific datasets (for example, only selfies) and transfer learn based on them.\n<br /><br />\nThe standard <a href=\"https://github.com/NVlabs/stylegan\">StyleGAN</a>  would not support running on CPU even in the generator mode where it does not need too much PC beef. So I found this little <a href=\"https://github.com/huaji0353/styleGAN_CPU\">patch</a> which allowed running the generator on a small machine without a GPU. \n<br /> <br />\n<h2 id=\"gpt-2\">GPT-2 <a class=\"direct-link\" href=\"#gpt-2\">#</a></h2>\n<p>I was going to use the biggest available GPT-2 XL (with 1.5 billion parameters) from <a href=\"https://huggingface.co/transformers/\">Huggingface</a>. However, when I made my first tests on the smallest GPT-2 with 134 million parameters I immediately liked the quality of the generated texts. I even ended up not fine-tuning the pretrained model further (however, I might explore this way in the future).<br>\n<br>\nAfter all, I wanted to match the average beauty blogger's post intelligence level, so no overkill was needed here. Slightly chaotic babble of the smallest GPT-2 suited the goal just fine.<br>\n<br>\nAnyway, the following models are available in the Transformers library (along with many other non-GPT ones):</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Parameters</th>\n<th>Size</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>gpt2</td>\n<td>134 M</td>\n<td>548 MB</td>\n</tr>\n<tr>\n<td>gpt2-medium</td>\n<td>335 M</td>\n<td>1.52 GB</td>\n</tr>\n<tr>\n<td>gpt2-large</td>\n<td>774 M</td>\n<td>3.25 GB</td>\n</tr>\n<tr>\n<td>gpt2-xl</td>\n<td>1.5 B</td>\n<td>6.43 GB</td>\n</tr>\n</tbody>\n</table>\n<br />\n<h2 id=\"under-the-hood\">Under the hood <a class=\"direct-link\" href=\"#under-the-hood\">#</a></h2>\n<p>The bot is written in Python using the amazing <a href=\"https://github.com/aiogram/aiogram\">aiogram</a> framework. It provides asynchronous processing and is very fast. The bot (narcissistically enough) does not currently listen to the user input and only posts the neural content to its Telegram channel. <br>\n<br>\nThe main bot application has been containerized with <a href=\"https://www.docker.com/\">Docker</a>. The StyleGAN and GPT-2 run in their respective Docker containers. First, I used the standard Tensorflow and Transformers images on Docker Hub, but ended up multistage building my own images because of the smaller resulting image size.<br>\n<br>\nAt first, all the containers used the same local bind mount. Then the neural generated content would be saved in the shared folder and picked up by the main app. It worked well, but smelled too much like the 1990-s. So now the Docker containers communicate using the <a href=\"https://redislabs.com/redis-best-practices/communication-patterns/pub-sub/\">Redis Pub/Sub</a> (Publisher/Subsriber paradigm). It is not only modern, fast and pretty but also flexible, so the app can be easily extended with more profound communication logic between the bot and neural networks. The Redis server also runs in its own Docker image.<br>\n<br>\nThe repo for the whole stuff is available <a href=\"https://github.com/guitargz/aidabot\">here</a> so feel free to have fun with it!</p>\n<p><img src=\"/img/aida_2.png\" alt=\"Look, it's smiling!\" title=\"Look, it's smiling!\"></p>\n",
      "date_published": "2021-04-19T00:00:00Z"
    },{
      "id": "https://guitargz.github.io/posts/202104101713-new-theme/",
      "url": "https://guitargz.github.io/posts/202104101713-new-theme/",
      "title": "New theme added",
      "content_html": "<p>Still learning Eleventy, quite excited about the possibilities and simplicity. Found and applied a cool minimal <a href=\"https://github.com/chesterhow/tale/\">Tale</a> theme.</p>\n",
      "date_published": "2021-04-10T00:00:00Z"
    },{
      "id": "https://guitargz.github.io/posts/202104092211%20The%20First%20Post/",
      "url": "https://guitargz.github.io/posts/202104092211%20The%20First%20Post/",
      "title": "First post - Hiya!",
      "content_html": "<p>Hello World!</p>\n<p>My name is Alex and this is my blog where I will write about the stuff I learn every day.<br>\nMainly this would be about programming and IT, but who knows - maybe some music or cats are also here eventually!<br>\nI am currently learning Eleventy which is the platform for this blog <a href=\"https://github.com/11ty/eleventy-base-blog\">(the eleventy-base-blog repo).</a></p>\n",
      "date_published": "2021-04-09T00:00:00Z"
    }
  ]
}
